%\VignetteIndexEntry{Vignette describing the CGD analysis from Komarek and Lesaffre (2004)}
\documentclass[a4paper]{article}

\usepackage{amsmath, amssymb, graphicx}

\setlength{\textheight}{9.8in}
\setlength{\textwidth}{6.23in}
\oddsidemargin=0mm
\evensidemargin=0mm
\topmargin=0mm
\hoffset=0mm
\voffset=-0.5in

\setlength{\parindent}{0pt}
\setlength{\parskip}{2mm}

\title{CGD Data: Recurrent Events Analysis \\ -- an analysis using the package \texttt{bayesSurv}}
\author{Arno\v{s}t Kom\'{a}rek}

\begin{document}

\maketitle
In this document we describe the analysis of CGD data presented in 
Section~4.1 of Kom\'arek and Lesaffre (2004).

We consider the following model
\begin{align*}
  \log(T_{i,l}) &= \beta_1\,trtmt_{i} + \beta_2\,inherit_{i} + \beta_3\,age_{i,l} +
   \beta_4\,cortico_{i} + \beta_5\,prophy_{i} + \beta_6\,(gender_i=female) + \\
  &\quad + \beta_7\,(hospital_i=US other) + \beta_8\,(hospit_i=EU Amsterdam) + \beta_9\,(hospit_i=EU other) + \\
  &\quad + b_i + \varepsilon_{i,l},
\end{align*}
where $i = 1,\dots, 128$ indexes patients and $l$ recurrent events on patients.

%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Initial data operations}
Firstly we load the package \texttt{bayesSurv}, read the data and do some arrangements.
<<initop1>>=
library(bayesSurv)
datadir <- paste(getwd(), "/cgd1", sep = "")
data <- read.table(paste(datadir, "/cgd.dat", sep = ""), header = TRUE,
                   colClasses = c(rep("numeric", 2), rep("character", 2), 
                                  rep("numeric", 13)))
print(data[1:6,])
@
For our analysis we change all 1-2 variables into 1-0 or 0-1 ones. Such that
\medskip
\begin{center}
\begin{tabular}{lcc}
\hline
Variable & $0$ & $1$ \\
\hline
\texttt{trtmt} & placebo & treatment \\
\texttt{gender} & male & female \\
\texttt{inherit} & X-linked & autosomal recessive \\
\texttt{cortico} & no & yes \\
\texttt{prophy} & no & yes \\
\texttt{event} & censored & obsered \\
\hline
\multicolumn{3}{c}{} \\
\end{tabular}
\end{center}
<<initop2>>=
data$trtmt <- -(data$trtmt - 2)                                 
data$gender <- data$gender - 1                                  
data$inherit <- data$inherit - 1                                
data$cortico <- -(data$cortico - 2)                             
data$prophy <- -(data$prophy - 2)                               
data$gender <- factor(data$gender, labels = c("male", "female"))
data$inherit <- factor(data$inherit, labels = c("X-l", "AuRec"))
data$hcat <- factor(data$hcat, labels = c("US-NIH", "US-other", "EU-Am", "EU-other"))

data$event <- -(data$event - 2) 
@ 
Further we compute times between two consecutive infections and define some additional variables.
<<initop3>>=
data$time <- data$T1 - data$T2
npatient <- length(unique(data$ID))
nobs <- dim(data)[1]
print(data[1:6,])
@ 


%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Finding reasonable values for prior hyperparameters}
To find reasonable values for prior hyperparameters we fit the log-normal AFT model
with and without random intercept using maximum likelihood:
<<fitinit1>>=
ifit <- survreg(Surv(time, event) ~ trtmt + inherit + age + cortico + prophy + gender + hcat + frailty(ID, dist = "gaussian"),
                dist = "lognormal", data = data)
resid <- ifit$y[, 1] - ifit$linear.predictors 
R <- max(resid) - min(resid)
ifit2 <- survreg(Surv(time, event) ~ trtmt + inherit + age + cortico + prophy + gender + hcat,
                 dist = "lognormal", data = data)
@ 
Summary for the model with the random intercept and the range of residuals:
<<fitinit2>>=
summary(ifit)
print(R)
@ 
Summary for the model without the random intercept:
<<fitinit3>>=
summary(ifit2)
@ 


%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Specification of priors}
To specify correctly the prior hyperparameters for $\beta$ parameters we have to know 
how the covariates are sorted in the design matrix. Normally, the same order should be
used as in the \texttt{formula} specification. However, one never knows\dots

The following command returns the design matrix and we look at first few rows
to see how are the covariates sorted in the columns. We also define the variable
\texttt{nregres} (number of covariates). The same model \texttt{formula} is used
as in the future function call.
<<prior1>>=
X <- bayessurvreg1(Surv(time, event) ~ trtmt + inherit + age + cortico + prophy + gender + hcat + cluster(ID),
                   random = ~1, data = data, onlyX = TRUE)
nregres <- dim(X)[2]
X[1:3,]
@ 
We see that $\beta_1 = trtmt$, $\beta_2 = inherit$ \dots $\beta_7 = hcat(US-other)$,
$\beta_8 = hcat(EU-Am)$, $\beta_9 = hcat(EU-other)$.

Now, we can start to specify the prior choices. These will be stored in \texttt{list}s.
For illustration purposes, we show also some other prior choices than these used
in Kom\'arek and Lesaffre (2004).

\subsection{Priors for the mixture}
<<mixprior1>>=
prior <- list()
@ 
Prior for the number of mixture components $k$ will be truncated Poisson($\lambda$, $k_{max}$) with $k_{max}=30$
and $\lambda = 5$. Alternative prior distribution would be uniform specified by 
\begin{verbatim}
prior$k.prior = ``uniform''
\end{verbatim}
<<mixprior2>>=
prior$kmax <- 30
prior$k.prior <- "poisson"
prior$poisson.k <- 5
@ 
Prior for mixture weights $w_1,\dots,w_k$ will be Dirichlet($\delta,\dots,\delta$) with $\delta = 1$.
<<mixprior3>>=
prior$dirichlet.w <- 1
@
Prior for mixture means $\mu_1,\dots,\mu_k$ will be N($\xi, \kappa$) with $\xi = 3.66$ 
(taken from \texttt{survreg(dist = "lognormal")} fit (approx intercept)) and $\kappa = 5^2 \approx (3\times 1.69)^2$
(1.69 was estimated scale parameter by \texttt{survreg}).
<<mixprior4>>=
prior$mean.mu <- 3.66
prior$var.mu <- 5^2
@ 
Prior for mixture inverse-variances $\sigma^{-2}_1,\dots,\sigma_k^{-2}$ will be Gamma$(\zeta, \eta)$
and prior for $\eta$ will be Gamma$(g,h)$, with $\zeta = 2.0$, $g=0.2$ and $h=0.1$. 
<<mixprior5>>=
prior$shape.invsig2 <- 2.0 
prior$shape.hyper.invsig2 <- 0.2
prior$rate.hyper.invsig2 <- 0.1
@ 
Probabilities of the split move (given current value of $k$) will be always $0.5$ except when $k=1$
or $k=k_{max}$.
<<mixprior6>>=
prior$pi.split <- c(1, rep(0.5, prior$kmax - 2), 0)
@ 
Probabilities of the birth move (given current value of $k$) will be always $0.5$ except when $k=1$
or $k=k_{max}$.
<<mixprior7>>=
prior$pi.birth <- c(1, rep(0.5, prior$kmax - 2), 0)
@ 
The last component of the \texttt{list} \texttt{prior} should be always set to 
\texttt{FALSE}. Its value equal to \texttt{TRUE} served only for some
exploratory purposes of the author.
<<mixprior8>>=
prior$Eb0.depend.mix <- FALSE
@ 
Look how it looks like:
<<mixprior9>>=
print(prior)
@ 

\subsection{Priors for regression parameters $\boldsymbol{\beta}$}
For illustration purposes, we define several \texttt{list}s with the same
prior specification (all $\boldsymbol{\beta}$ parameters are assigned 
N$(0, 1000)$ prior)
however with different possibilities how to update
the $\boldsymbol{\beta}$ parameters in the MCMC simulation.

\subsubsection{All $\boldsymbol{\beta}$ parameters updated using the Gibbs step}
With the first specification, all $\boldsymbol{\beta}$ will be updated
in one block using the Gibbs move. This is usually a~recommended choice
and was also used to get results presented in Kom\'arek and Lesaffre (2004).
<<betaprior1>>=
prior.beta.gibbs <- list()
prior.beta.gibbs$mean.prior <- rep(0, nregres)
prior.beta.gibbs$var.prior <- rep(1e3, nregres)
@ 
Look how it looks like:
<<betaprior2>>=
print(prior.beta.gibbs)
@ 

\subsubsection{All $\boldsymbol{\beta}$ parameters updated in one block using random walk Metropolis-Hastings step}
With the second specification, all $\boldsymbol{\beta}$ parameters would be updated
in one block using a~random walk Metropolis-Hastings step with a~proposal 
covariance matrix \texttt{covm}. 
<<betaprior3>>=
prior.beta.mh1 <- list()
prior.beta.mh1$mean.prior <- rep(0, nregres)
prior.beta.mh1$var.prior <- rep(1e3, nregres)
@ 
Definition of blocks in which beta parameters will be updated
and the way in which they will be updated:
<<betaprior4>>=
prior.beta.mh1$blocks <- list()
prior.beta.mh1$blocks$ind.block <- list()
@ 
There is only one block that contains beta[1:9]:
<<betaprior5>>=
prior.beta.mh1$blocks$ind.block[[1]] <- 1:9            
nblock <- length(prior.beta.mh1$blocks$ind.block)
@ 
Further we define a proposal covariance matrix.
\begin{center}
\begin{tabular}{rcl}
\texttt{vars} & $=$ & proposal variances for each beta parameter \\
\texttt{cors} & $=$ & lower triangle of the proposal correlation matrix \\
\texttt{corsm} & $=$ &  proposal correlation matrix itself \\
\texttt{covm} & $=$ & proposal covariance matrix \\
&& \\
\end{tabular}
\end{center}
<<betaprior6>>=
vars <- c(0.15, 0.20, 0.0003, 1.3, 0.08, 0.25, 0.1, 0.35, 0.35)
cors <- c(1,  0.1,  0,     0.1,  0.15, 0,    0.4, 0.1, 0.2,
          1, -0.15, 0.15, -0.2, -0.3,  0.2, -0.1, 0,
          1, -0.2,  0.15,  0.2,  0.3,  0.2,  0.1,
          1,  0.2, -0.5,   0.2, -0.4,  0.4,
          1,  0.15, 0.5,   0.3,  0.4,
          1,  0.15, 0.15,  0,
          1,  0.35, 0.65,
          1,  0.2,
          1)
corsm <- diag(9)
corsm[lower.tri(corsm, diag = TRUE)] <- cors
corsm[upper.tri(corsm, diag = FALSE)] <- t(corsm)[upper.tri(t(corsm), diag = FALSE)]
covm <- diag(sqrt(vars)) %*% corsm %*% diag(sqrt(vars))
@ 
Here is the proposal correlation matrix:
<<betaprior7>>=
print(corsm)
@ 
Here is the proposal covariance matrix:
<<betaprior8>>=
print(round(covm, digits=3))
@ 
Now we put a lower triangle of the proposal covariance matrix to the resulting list.
\texttt{cov.prop} component of the resulting list is again a list, now with only one component
since there is only one block of regression parameters.
Observe that only lower traingle of each proposal covariance matrix must be supplied.
<<betaprior9>>=
prior.beta.mh1$blocks$cov.prop <- list()
prior.beta.mh1$blocks$cov.prop[[1]] <- covm[lower.tri(covm, diag = TRUE)]
@ 
Further, we have to say that all blocks (one here) will be updated using a random-walk Metropolis algorithm
(default would be Gibbs).
<<betaprior10>>=
prior.beta.mh1$type.upd <- rep("random.walk.metropolis", nblock)
@ 
Subsequently, we have to say how a normal proposal will be mixed with a uniform proposal
when updating each block of parameters.  We specify weights of a uniform component (here 0.05 for our one block).
You can set each weight to zero if you do not want to mix normal and uniform proposals
<<betaprior11>>=
prior.beta.mh1$weight.unif <- rep(0.05, nblock)   
@ 
Finally, we have to specify half of a range of a uniform component proposal for each
regression parameter, i.e. we have to supply a vector of length 9.
<<betaprior12>>=
prior.beta.mh1$half.range.unif <- c(0.25, 0.25, 0.01, 1.0, 0.15, 0.25, 0.3, 1.0, 1.0) 
@ 
Look how it looks like:
<<betaprior13>>=
print(prior.beta.mh1)
@ 

\subsubsection{$\boldsymbol{\beta}$ updated in two blocks using random walk Metropolis-Hastings step}
Finally, we show how to specify the prior \texttt{list} for the situation we wish to update 
$\boldsymbol{\beta}$ parameters in two blocks, first of them updated using a~Gibbs step,
the second one using a~random walk Metropolis-Hastings step.
<<betaprior14>>=
prior.beta.mh2 <- list()
prior.beta.mh2$mean.prior <- rep(0, nregres)
prior.beta.mh2$var.prior <- rep(1e3, nregres)
@ 
Definition of blocks in which beta parameters will be updated
(two blocks -- \texttt{beta[1:6]} and \texttt{beta[7:9]})
and the way in which they will be updated.
<<betaprior15>>=
prior.beta.mh2$blocks <- list()
prior.beta.mh2$blocks$ind.block <- list()
prior.beta.mh2$blocks$ind.block[[1]] <- 1:6 
prior.beta.mh2$blocks$ind.block[[2]] <- 7:9 
nblock <- length(prior.beta.mh2$blocks$ind.block)
@ 
Further we define a proposal covariance matrix for the second block.
Note that the proposal covariance matrix for the first block does not have to be defined
since the first block is updated using a Gibbs move.
\begin{center}
\begin{tabular}{rcl}
\texttt{vars} & $=$ & proposal variances for each beta[7:9] parameter \\
\texttt{cors} & $=$ & lower triangle of the proposal correlation matrix \\
\texttt{corsm} & $=$ &  proposal correlation matrix itself \\
\texttt{covm} & $=$ & proposal covariance matrix \\
&& \\
\end{tabular}
\end{center}
<<betaprior16>>=
vars <- c(0.1, 0.35, 0.35)
cors <- c(1, 0.9, 0.9,
          1, 0.9,
          1)
corsm <- diag(3)
corsm[lower.tri(corsm, diag = TRUE)] <- cors
corsm[upper.tri(corsm, diag = FALSE)] <- t(corsm)[upper.tri(t(corsm), diag = FALSE)]
covm <- diag(sqrt(vars)) %*% corsm %*% diag(sqrt(vars))
@ 
Here is the proposal correlation matrix for the second block of \texttt{beta} parameters:
<<betaprior17>>=
print(corsm)
@ 
Here is the proposal covariance matrix for the second block of \texttt{beta} parameters:
<<betaprior18>>=
print(covm)
@ 
Now we put a lower triangle of the proposal covariance matrix to the resulting list.
\texttt{cov.prop} component of the resulting list is again a list, now with two components (we have 2 blocks).
Note that the first component of \texttt{cov.prop} may be set to \texttt{NULL} since we intend to use Gibbs step for the first
block and no proposal covariance matrix is thus needed.
Further, only lower traingle of each proposal covariance matrix must be supplied.
<<betaprior19>>=
prior.beta.mh2$blocks$cov.prop <- list()
prior.beta.mh2$blocks$cov.prop[[1]] <- NULL
prior.beta.mh2$blocks$cov.prop[[2]] <- covm[lower.tri(covm, diag = TRUE)]
@ 
Further, we have to say that the first block will be updated using the Gibbs move
and the second block using random-walk Metropolis.
<<betaprior20>>=
prior.beta.mh2$type.upd <- c("gibbs", "random.walk.metropolis")
@ 
Subsequently, we have to say how a normal proposal will be mixed with a uniform proposal
when updating each block of parameters.
So we specify weights of a uniform component (here 0.05 for our second block).
Note that the first component of this vector will be ignored since the first block is updated using
Gibbs move.
<<betaprior21>>=
prior.beta.mh2$weight.unif <- c(0.05, 0.05)   
@ 
Finally, we have to specify half of a range of a uniform component proposal for each
regression parameter, i.e. we have to supply a vector of length 9.
Again, first 6 components of this vector will be ignored since the first block is
updated using the Gibbs move.
<<betaprior22>>=
prior.beta.mh2$half.range.unif <- c(0.25, 0.25, 0.01, 1.0, 0.15, 0.25, 0.3, 1.0, 1.0) 
@ 
Look how it looks like:
<<betaprior23>>=
print(prior.beta.mh2)
@ 

\section{Prior specification for the random intercept $b_i$ related parameters}
The following \texttt{list} has only to specify two prior hyperparameters for the covariance matrix
$\mathbb{D}$ (which is a~scalar here, let say $d$) and to say how the individual random effects will be updated.

\subsection{Inverse-gamma prior distribution for $d$}
<<bprior1>>=
prior.b.gamma <- list()
@ 
Hyperparameters for $d$ are degrees of freedom $\tau$ and scale parameter $\mathbb S = s$. Here,
$\tau = 0.002$ and $s = 0.002$ which results in inverse-gamma$(0.001, 0.001)$ prior for $d$.
Remember that inverse-Wishart($\tau$, invscale = $1/s$) = inverse-gamma($\tau/2$, scale = $s/2$)
and Wishart($\tau$, scale = $s$) = gamma($\tau/2$, scale = $2/s$) = gamma($\tau/2$, rate = $s/2$).
<<bprior2>>=
prior.b.gamma$prior.D <- "inv.wishart"
prior.b.gamma$df.D <- 0.002                    # tau = degrees of freedom of an inverse-Wishart distribution
prior.b.gamma$scale.D <- 0.002                 # sb = scale of an inverse-Wishart distribution
@ 
Type of the update of the random intercept will be Gibbs move (this could be omitted since it is a default choice).
<<bprior3>>=
prior.b.gamma$type.upd <- "gibbs"
@ 
Look how it looks like:
<<bprior4>>=
print(prior.b.gamma)
@ 

\subsection{Uniform distribution for $\sqrt{d}$}
This prior choice gives much better results than the previous one. A~uniform prior (here Unif$(0, 100)$) is used
for the standard deviation ($\sqrt{d}$) of the random intercept.
<<bprior5>>=
prior.b.unif <- list()
prior.b.unif$prior.D <- "sduniform"
@ 
Upper limit for the prior uniform distribution of $\sqrt{d}$:
<<bprior6>>=
prior.b.unif$scale.D <- 100
@ 
Type of the update of individual random effects:
<<bprior6b>>=
prior.b.unif$type.upd <- "gibbs"
@ 
Look how it looks like:
<<bprior7>>=
print(prior.b.unif)
@ 

\subsection{Parameters to perform reversible jumps}
<<revjump1>>=
prop.revjump <- list()
@ 
Type of the algorithm:
<<revjump2>>=
prop.revjump$algorithm <- "correlated.av"
@ 
Parameters of a moody ring ($\epsilon$, $delta$, see paper Brooks et al. (2003) for details).
Remember, $\epsilon$ = time dependence, $\delta$ = component dependence.
<<revjump3>>=
prop.revjump$moody.ring <- c(0.1, 0.05)
@ 
Transformation of a canonical seed for split-combine move:
<<revjump4>>=
prop.revjump$transform.split.combine <- "brooks"
prop.revjump$transform.split.combine.parms <- c(2, 2, 2, 2, 1, 1)
@ 
Transformation of a canonical seed for birth-death move:
<<revjump5>>=
prop.revjump$transform.birth.death <- "richardson.green"
@ 
Look how it looks like:
<<revjump6>>=
print(prop.revjump)
@ 

%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Specification of initial values for the MCMC}
We give two sets of initial values to run two chains. Undefined initials 
are sampled automatically by the program.

\subsection{Initials for chain 1}
<<init11>>=
init1 <- list()
@ 
Iteration number of the nulth iteration:
<<init12>>=
init1$iter <- 0
@ 
Initial mixture (from \texttt{survreg(dist = "lognormal")}). It will have one component
with $w_1 = 1$, $\mu_1 = 3.9$ and $\sigma_1^2 = 1.2$.
<<init13>>=
init1$mixture <- c(1,
                   1, rep(0, prior$kmax - 1),
                   3.9, rep(0, prior$kmax - 1),
                   1.2, rep(0, prior$kmax - 1))
@ 
Initial regression parameters $\boldsymbol{\beta}$ (from \texttt{survreg(dist = "lognormal")}):
<<init14>>=
init1$beta <- c(1.1, -0.66, 0.04, -1.76, 0.94, 1.03, 0.37, 1.22, 0.82)
@ 
Initial variance $d$ of the random intercept $b_i$:
<<init15>>=
init1$D <- 0.16
@ 
Initial values of a random intercept for each of 128 patients.
Here, use zero for all patients.
<<init16>>=
init1$b <- rep(0, npatient)    
@ 
Initial (augmented) log(event) times -- let the program sample them:
<<init17>>=
init1$y <- NULL
@ 
Initial component pertinence of the observations to the mixture (all observations
belong to the first component):
<<init18>>=
init1$r <- rep(1, nobs)
@ 
Initial value of a hyperparameter $\eta$ (sample it from a prior distribution):
<<init19>>=
init1$otherp <- rgamma(1, shape = prior$shape.hyper.invsig2, rate = prior$rate.hyper.invsig2)
@ 
Initial values of canonical variables for reversible move (sample it from a uniform distribution):
<<init110>>=
init1$u <- c(runif(1), 0, 0, runif(3*(prior$kmax - 1)))
@ 
Look how it look like:
<<init111>>=
print(init1)
@ 

\subsection{Initials for chain 2}
<<init21>>=
init2 <- list()
@ 
Iteration number of the nulth iteration:
<<init22>>=
init2$iter <- 0
@ 
Initial mixture, now with two components and $w_1 = w_2 = 0.5$, $\mu_1 = 2.5$, $\mu_2 = 5.5$,
$\sigma_1^2 = \sigma_2^2 = 1$:
<<init23>>=
init2$mixture <- c(2,
                   0.5, 0.5, rep(0, prior$kmax - 2),
                   2.5, 5.5, rep(0, prior$kmax - 2),
                   1, 1, rep(0, prior$kmax - 2))
@ 
Initial regression parameters $\boldsymbol{\beta}$ (all zeros here):
<<init24>>=
init2$beta <- rep(0, nregres)
@ 
Initial variance $d$ of the random intercept $b_i$:
<<init25>>=
init2$D <- 0.05
@ 
Initial values of a random intercept for each of 128 patients (sample it from a normal distribution):
<<init26>>=
init2$b <- rnorm(npatient, 0, sqrt(init2$D))
@ 
Initial (augmented) log(event) times -- let the program sample them:
<<init27>>=
init2$y <- NULL
@ 
Initial component pertinence of the observations to the mixture (half observations to the first component, half to the second component):
<<init28>>=
init2$r <- c(rep(1, 102), rep(2, 101))
@ 
Initial value of a hyperparameter $\eta$ (sample it from a prior distribution):
<<init29>>=
init2$otherp <- rgamma(1, shape = prior$shape.hyper.invsig2, rate = prior$rate.hyper.invsig2)
@ 
Initial values of canonical variables for reversible move (sample it from a uniform distribution):
<<init210>>=
init2$u <- c(runif(1), 0, 0, runif(3*(prior$kmax - 1)))
@ 


%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Running the MCMC simulation}
Now we are ready to run the MCMC to sample from the posterior distribution.

Here we define which quantities that are not neccessarily needed for the inference
will be stored. With this specification, we store only sampled values of individual
values of random effects for each patient.
<<forrun1>>=
store <- list(y = FALSE, r = FALSE, u = FALSE, b = TRUE, MHb = FALSE, regresres = FALSE)
@ 
How long simulation we want to run? For testing purposes, only limited simulation
is specified here. 
<<forrun2>>=
nsimul <- list(niter = 1000, nthin = 3, nburn = 500, nnoadapt = 0, nwrite = 500)
@ 
For the analysis presented in Kom\'arek and Lesaffre (2004) we used
\begin{verbatim}
> nsimul <- list(niter = 60000, nthin = 6, nburn = 30000, nnoadapt = 0, nwrite = 1000)
\end{verbatim}
which performed 6$\times$30\,000 iterations of burn-in and additionally 6$\times$30\,000 iterations from which 
each 6th value was stored. Further, after cumulating 1\,000 sampled values, these were stored on a disk.
This would last about 15 minutes on 2GHz machine.

Define directories where first and second chain will be stored. We first create these directories:
<<forrun3>>=
dir.create("cgdchain1")
dir.create("cgdchain2")
dirsim1 <- paste(getwd(), "/cgdchain1", sep = "")
dirsim2 <- paste(getwd(), "/cgdchain2", sep = "")
@ 
Run the simulation for the first and the second chain.
<<runsimChain1, term=FALSE>>=
simul1 <- bayessurvreg1(Surv(time, event) ~ trtmt + inherit + age + cortico + prophy + gender + hcat + cluster(ID),
                        random = ~1,
                        data = data, dir = dirsim1, nsimul = nsimul,
                        prior = prior, prior.beta = prior.beta.gibbs, prior.b = prior.b.unif, prop.revjump = prop.revjump,
                        init = init1, store = store)
<<runsimChain2, term=FALSE>>=
simul2 <- bayessurvreg1(Surv(time, event) ~ trtmt + inherit + age + cortico + prophy + gender + hcat + cluster(ID),
                        random = ~1,
                        data = data, dir = dirsim2, nsimul = nsimul,
                        prior = prior, prior.beta = prior.beta.gibbs, prior.b = prior.b.unif, prop.revjump = prop.revjump,
                        init = init2, store = store)
@ 

%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Running additional MCMC simulation to compute predictive quantities}
First we have to define covariate values for which we want to do a prediction.
Here, we want 8 predictive distributions, for each combination of 
treatment/placebo $\times$ X-linked/autosomal recessive pattern of inheritance $\times$ male/female.
Remaining covariates are set to modus/mean values (age = 14.6, no corticosteroids, yes prophylactic antibiotica, hospital category = US-other).
Time (response) variable is set to 1 for all 'new' patients (it does not matter what it is set to).
Event variable is set to 0 for all 'new' patients (again, it does not matter, provided that \texttt{Surv}
is subsequently able to create a survival object from such 'new' data).
<<predict1>>=
nnewpat <- 8
nID <- 1:nnewpat
ntrtmt <-          c(0, 1, 0, 1, 0, 1, 0, 1)
ninherit <- factor(c(0, 0, 1, 1, 0, 0, 1, 1), levels = 0:1, labels = c("X-l", "AuRec"))
nage <- rep(14.6, nnewpat)
ncortico <- rep(0, nnewpat)
nprophy <- rep(1, nnewpat)
ngender <-  factor(c(0, 0, 0, 0, 1, 1, 1, 1), levels = 0:1, labels = c("male", "female"))
nhcat <- factor(rep(2, nnewpat), levels = 1:4, labels = c("US-NIH", "US-other", "EU-Am", "EU-other"))

ntime <- rep(1, nnewpat)
nevent <- rep(0, nnewpat)
@ 
Data frame with 'new' data:
<<predict2>>=
preddata <- data.frame(ID = nID, trtmt = ntrtmt, inherit = ninherit, age = nage, cortico = ncortico, prophy = nprophy,
                       gender = ngender, hcat = nhcat, time = ntime, event = nevent)
print(preddata)
@ 
Further, we specify what we want to predict (with this, survivor function and hazard function).
Also, specify whether sampled quantities should be stored, otherwise, only quantiles and predictive means
are computed (which usually suffice).
<<predict3>>=
predict <- list(Et = TRUE, t = FALSE, Surv = TRUE, hazard = TRUE, cum.hazard = FALSE)
store <- list(Et = FALSE, t = FALSE, Surv = FALSE, hazard = FALSE, cum.hazard = FALSE)
@ 
Grid of values in which predictive survivor and hazard curves should be computed:
<<predict4>>=
grid <- seq(1, 401, by = 2.5)
@ 
How many MCMC iterations we want to perform (\texttt{niter} should be $\leq$ length of already sampled chain)
and how often should sampled quantities be written to disk
<<predict5>>=
nsimul.pred <- list(niter = nsimul$niter-nsimul$nburn, nwrite = nsimul$niter-nsimul$nburn)
@ 
Run MCMC simulation to sample from the predictive distribution (only chain 1 will be used here):
<<runPredict>>=
simulp <- predictive(Surv(time, event) ~ trtmt + inherit + age + cortico + prophy + gender + hcat + cluster(ID),
                     random = ~1, data = preddata, dir = dirsim1,
                     quantile = c(0, 0.025, 0.5, 0.975, 1),
                     nsimul = nsimul.pred, predict = predict, store = store, grid = grid,
                     Eb0.depend.mix = FALSE, type = "mixture")
@ 
In a directory \texttt{./cgdchain1} few new files should appear: 
\begin{itemize}
\item \texttt{quantS1.sim} -- \texttt{quantS8.sim};
\item \texttt{quanthazard1.sim} -- \texttt{quanthazard8.sim};
\item \texttt{quantET.sim}.
\end{itemize}
Files \texttt{quantS*.sim} and \texttt{quanthazard*.sim} contain pointwise (evaluated at the grid specified above)
posterior predictive quantiles and means of the survivor and hazard function
for each combination of covariates specified in \texttt{preddata}.
File \texttt{quantET.sim} contains posterior predictive quantiles and mean for expected
survivor time of each combination of covariates.
Note that
\begin{enumerate}
\item There is one file per survivor/hazard function and per covariate combination.
Indeces of these files (1, ..., 8) correspond to rows of \texttt{preddata}.
Structure of these files is following
\begin{center}
\begin{tabular}{rcl}
 1st row & $=$ & grid values \\
 2nd row & $=$ & post. predictive 0\% quantile (minimum) \\
 3rd row & $=$ & post. predictive 2.5\% quantile \\
 4th row & $=$ & post. predictive 50\% quantile (median) \\
 5th row & $=$ & post. predictive 97.5\% quantile \\
 6th row & $=$ & post. predictive 100\% quantile (maximum) \\
 last row & $=$ & post. predictive mean \\
\end{tabular}
\end{center}
\item There is only one file for posterior predictive expected survivor times
and all combinations of covariates (\texttt{quantET.sim}).
Structure of this file is following:
\begin{center}
\begin{tabular}{rcl}
 1st row & $=$ & character labels ET1 - ET8  \\
          && indicating that each column corresponds  \\
          && to one covariate combination \\
 remaining rows & $=$ & same as for \texttt{quantS*.sim} or \texttt{quanthazard*.sim} \\
\end{tabular}
\end{center}
\end{enumerate}
\bigskip
You might specify also other quantiles (parameter \texttt{quantile} in function \texttt{predictive}) to be computed.
Posterior predictive mean is always computed and stored on the last row.


%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Drawing posterior predictive survivor/hazard curves}
%<<tempdir, echo=FALSE>>=
%dirsim1 <- paste(getwd(), "/longcgd1Chain1", sep = "")
%dirsim2 <- paste(getwd(), "/longcgd1Chain2", sep = "")
@ 
In this section we draw posterior predictive survivor and hazard curves for new patients
with covariate combinations defined in the previous section.

Posterior predictive survivor curve and its 95\% pointwise CI
(1 plot per covariate combination). 
The result is given in Figure~\ref{fig1}.
<<fig1, fig=TRUE, width=9.5, height=10, include=FALSE>>=
labels <- c("Male, X-l, plcb", "Male, X-l, trt", "Male, AR, plcb", "Male, AR, trt",
            "Female, X-l, plcb", "Female, X-l, trt", "Female, AR, plcb", "Female, AR, trt")
par(mfrow = c(4, 2))
for(i in 1:8){
  gridS <- scan(paste(dirsim1, "/quantS", i, ".sim", sep = ""), nlines = 1) 
  Sfun <- read.table(paste(dirsim1, "/quantS", i, ".sim", sep = ""), header = TRUE)
  rownames(Sfun) <- c("0%", "2.5%", "50%", "97.5%", "100%", "mean")
  plot(gridS, Sfun["mean", ], type = "l", lty = 1, ylim = c(0, 1), xlab = "Time (days)", ylab = "Survivor", bty = "n")  
  lines(gridS, Sfun["2.5%", ], lty = 2)
  lines(gridS, Sfun["97.5%", ], lty = 2)
  title(main = labels[i])
}  
@ 
\begin{figure}[tb]
\caption{Posterior predictive survivor curves and their 95\% pointwise CI.}
\label{fig1}
\begin{center}
\includegraphics[height=5in, width=6.5in]{cgd1-fig1}
\end{center}
\end{figure}

Posterior predictive hazard curve and its 95\% pointwise CI
(1 plot per covariate combination).
The result is given in Figure~\ref{fig2}.
<<fig2, fig=TRUE, width=9.5, height=10, include=FALSE>>=
labels <- c("Male, X-l, plcb", "Male, X-l, trt", "Male, AR, plcb", "Male, AR, trt",
            "Female, X-l, plcb", "Female, X-l, trt", "Female, AR, plcb", "Female, AR, trt")
par(mfrow = c(4, 2))
for(i in 1:8){
  gridhaz <- scan(paste(dirsim1, "/quanthazard", i, ".sim", sep = ""), nlines = 1) 
  hfun <- read.table(paste(dirsim1, "/quanthazard", i, ".sim", sep = ""), header = TRUE)
  rownames(hfun) <- c("0%", "2.5%", "50%", "97.5%", "100%", "mean")
  plot(gridhaz, hfun["97.5%", ], type = "l", lty = 2, xlab = "Time (days)", ylab = "Hazard", bty = "n")  
  lines(gridhaz, hfun["mean", ], lty = 1)
  lines(gridhaz, hfun["2.5%", ], lty = 2)
  title(main = labels[i])
}  
@ 
\begin{figure}
\caption{Posterior predictive hazard curves and their 95\% pointwise CI}
\label{fig2}
\begin{center}
\includegraphics[height=5in, width=6.5in]{cgd1-fig2}
\end{center}
\end{figure}

Posterior predictive survivor curves
(1 plot per gender with 4 curves on it).
The result is given in Figure~\ref{fig3}.
<<fig3, fig=TRUE, width=9.5, height=10, include=FALSE>>=
gg <- c("Male", "Female")
par(mfrow = c(2, 1))
for (j in 1:2){
  for(i in 1:4){
    gridS <- scan(paste(dirsim1, "/quantS", (j-1)*4+i, ".sim", sep = ""), nlines = 1) 
    Sfun <- read.table(paste(dirsim1, "/quantS", (j-1)*4+i, ".sim", sep = ""), header = TRUE)
    rownames(Sfun) <- c("0%", "2.5%", "50%", "97.5%", "100%", "mean")
    if (i == 1) plot(gridS, Sfun["mean", ], type = "l", lty = 1, ylim = c(0, 1), xlab = "Time (days)", ylab = "Survivor", bty = "n")
    else        lines(gridS, Sfun["mean", ], lty = i)
    legend(0, 0.6, legend = c("trtmt, X-l", "trtmt, AuRec", "placebo, X-l", "placebo, AuRec"), lty = c(2, 4, 1, 3), bty = "n")
  }
  title(main = gg[j])
}  
@ 
\begin{figure}
\caption{Posterior predictive survivor curves.}
\label{fig3}
\begin{center}
\includegraphics[height=5in, width=6.5in]{cgd1-fig3}
\end{center}
\end{figure}

Posterior predictive hazard curves
(1 plot per gender with 4 curves on it).
The result is given in Figure~\ref{fig4}.
<<fig4, fig=TRUE, width=9.5, height=10, include=FALSE>>=
gg <- c("Male", "Female")
par(mfrow = c(2, 1))
leg <- c(0.0080, 0.0040)
ylim <- c(0.0100, 0.0040)
for (j in 1:2){
  for(i in 1:4){
    gridhaz <- scan(paste(dirsim1, "/quanthazard", (j-1)*4+i, ".sim", sep = ""), nlines = 1) 
    hfun <- read.table(paste(dirsim1, "/quanthazard", (j-1)*4+i, ".sim", sep = ""), header = TRUE)
    rownames(hfun) <- c("0%", "2.5%", "50%", "97.5%", "100%", "mean")
    if (i == 1) plot(gridhaz, hfun["mean", ], type = "l", lty = 1, ylim = c(0, ylim[j]), xlab = "Time (days)", ylab = "Hazard", bty = "n")
    else        lines(gridhaz, hfun["mean", ], lty = i)
    legend(200, leg[j], legend = c("trtmt, X-l", "trtmt, AuRec", "placebo, X-l", "placebo, AuRec"), lty = c(2, 4, 1, 3), bty = "n")
  }
  title(main = gg[j])
}  
@ 
\begin{figure}
\caption{Posterior predictive hazard curves.}
\label{fig4}
\begin{center}
\includegraphics[height=5in, width=6.5in]{cgd1-fig4}
\end{center}
\end{figure}


%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Computing and drawing predictive error density}

Here, we compute posterior standardized (zero mean, unit variance) and unstandardized 
predictive error densities, separately for each chain. Vector \texttt{dgrid}
is a~grid of values where the unstandardized density is to be evaluated,
vector \texttt{dgrids} is a~grid of values where the standardized density 
is to be evaluated.
<<predError1, term=FALSE>>=
dgrid <- seq(-2, 9, length = 100)
dgrids <- seq(-3, 3, length = 100)
dens <- list()
for (ch in 1:2){
  dens[[ch]] <- bayesDensity(dir = get(paste("dirsim", ch, sep = "")), grid = dgrid, stgrid = dgrids)
}  
@ 

Now, we plot first the unstandardized predictive error densities for each chain 
and then the standardized ones
(conditional densities given $k$ are plotted only for $k = 1,\dots, 9$).
The result is seen in Figure~\ref{figdens}.
<<fig5, fig=TRUE, width=9.5, height=10, include=FALSE>>=
par(bty = "n", mfrow = c(2, 2))
for (ch in 1:2){
  xlim <- c(-2, 8); xleg <- -2; yleg <- 0.3; ylim <- c(0, 0.3)
  plot(dens[[ch]], k.cond = 0:9, standard = FALSE, dim.plot = FALSE, xlim = xlim, ylim = ylim, xleg = xleg, yleg = yleg, main = "")
  title(main = paste("Unstandardized, Chain ", ch, sep = ""))
}
for (ch in 1:2){
  xlim <- c(-2.5, 2.5); xleg <- -2.5; yleg <- 0.7; ylim <- c(0, 0.7)
  plot(dens[[ch]], k.cond = 0:9, standard = TRUE, dim.plot = FALSE, xlim = xlim, ylim = ylim, xleg = xleg, yleg = yleg, main = "")
  title(main = paste("Standardized, Chain ", ch, sep = ""))
}
@
\begin{figure}[t]
\caption{Predictive error densities.}
\label{figdens}.
\begin{center}
\includegraphics[height=5in, width=6.5in]{cgd1-fig5}
\end{center}
\end{figure}


%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Predictive values of individual random effects $b_i$}
Sampled individual random effects (from both chains):
<<predb1>>=
ids <- unique(data$ID)
bb <- list()
for (ch in 1:2){
  bb[[ch]] <- matrix(scan(paste(get(paste("dirsim", ch, sep = "")), "/b.sim", sep = ""), skip = 1), ncol = 128, byrow = TRUE)
  colnames(bb[[ch]]) <- ids
} 
bbs <- rbind(bb[[1]], bb[[2]])
@ 
Compute the posterior mean and some quantiles for each individual
random effect:
<<predb2>>=
b.mean <- apply(bbs, 2, mean)
b.median <- apply(bbs, 2, quantile, 0.50)
b.low <- apply(bbs, 2, quantile, 0.025)
b.up <- apply(bbs, 2, quantile, 0.975)
@ 
Sort patients according to number of events:
<<predb3>>=
n <- dim(data)[1]
id1 <- data$ID[1:(n-1)]; id2 <- data$ID[2:n]; difid <- c(1, id2 - id1)
first <- difid > 0           
frevent <- table(data$ID)
freqv <- as.numeric(frevent)
frval <- data.frame(ID = data$ID[first], trtmt = data$trtmt[first], freq = as.numeric(frevent),
                    b.mean, b.median, b.low, b.up, nevent = freqv)
frval <- frval[order(frval$trtmt), ]
frval <- frval[order(frval$freq), ]
@ 

Plot means and 95\% CI for each individual random effect $b_i$ (see Figure~\ref{fig15} for the result).
<<fig15, fig=TRUE, width=8, height=8, include=FALSE>>=
par(bty="n")
plot(frval$b.mean, 1:128, type = "p", pch = 20, xlim = c(-3, 2.5), bty = "n", ylab = "Patient", xlab = "Random effect")
lines(frval$b.mean, 1:128)
points(frval$b.low, 1:128, pch = 15, cex = 0.5)
points(frval$b.up, 1:128, pch = 15, cex = 0.5)
for (pat in 1:n){
  lines(c(frval$b.low[pat], frval$b.up[pat]), c(pat, pat), lty = 1)
}
title(main = "Individual random effects")
abline(h = 84.5, lty = 2)
abline(h = 112.5, lty = 2)
abline(h = 120.5, lty = 2)
abline(v = 0, lty = 1)
text(-3, 40, "1 event", pos = 4)
text(-3, 30, "/patient", pos = 4)
text(-3, 100,  "2 events", pos = 4)
text(-3, 90, "/patient", pos = 4)
text(-3, 115, "3", pos = 4)
text(-3, 127, ">= 4", pos = 4)  
@ 
\begin{figure}[tb]
\caption{Individual random effects $b_i$.}
\label{fig15}.
\begin{center}
\includegraphics[height=4in, width=5in]{cgd1-fig15}
\end{center}
\end{figure}


%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Summary statistics and convergence diagnostics }
Now we compute some summary statistics and perform some convergence diagnostics
using the {\scshape R} package \texttt{coda}.

First, we load the \texttt{coda} package and say how many chains we have:
<<summ1>>=
library(coda)
nchains <- 2
@ 
Here we compute separately chains with the standard deviation $\sqrt{d}$ of the random intercept $b_i$
(only the variance $d$ is stored in the file \texttt{D.sim}).
Further, we compute the log-scale of the mixture (only the variance of the whole mixture is stored in the file \texttt{mixmoment.sim}).
<<summ2>>=
sdb <- list()
logscale <- list()
for (ch in 1:nchains){
  sdb[[ch]] <- read.table(paste(get(paste("dirsim", ch, sep = "")), "/D.sim", sep = ""), header = TRUE)
  sdb[[ch]] <- data.frame(sdb = sqrt(sdb[[ch]][,2]))
  logscale[[ch]] <- read.table(paste(get(paste("dirsim", ch, sep = "")), "/mixmoment.sim", sep = ""), header = TRUE)
  logscale[[ch]] <- data.frame(logscale = sqrt(logscale[[ch]][,2]))
}  
@ 
Using the function \texttt{files2coda} we create the CODA \texttt{mcmc} objects for each parameter
and each chain:
<<summ3>>=
pars <- list()
for (ch in 1:nchains){
  pars[[ch]] <- files2coda(files = c("beta.sim", "mixmoment.sim"), data.frames = c("sdb", "logscale"),
                           thin = 1, dir = paste(get(paste("dirsim", ch, sep = ""))), chain = ch)
}
@ 
We combine both chains into a CODA \texttt{mcmc.list}:
<<summ4>>=
parsls <- mcmc.list(pars[[1]], pars[[2]])
rm(list = c("pars", "sdb", "logscale"))
@ 
Look what are the model parameters stored in this object:
<<summ5>>=
dimnames(parsls[[1]])[[2]]
@ 

\subsection{Summary statistics}
Summary statistics (separately for each chain):
<<summ6>>=
quant <- c(0, 0.025, 0.5, 0.75, 0.975, 1)
means <- list();  quantiles <- list();  summ <- list()
for (ch in 1:nchains){
  means[[ch]] <- apply(parsls[[ch]], 2, mean)
  quantiles[[ch]] <- apply(parsls[[ch]], 2, quantile, quant)
  summ[[ch]] <- rbind(means[[ch]], quantiles[[ch]])
  rownames(summ[[ch]])[1] <- "mean"
}  
names(summ) <- paste("Chain ", 1:nchains, sep = "")
print(summ)
@ 

\subsection{Posterior densities}
Histogram of sampled $k$ (number of mixture components). The result is shown in Figure~\ref{fig6}.
<<fig6, fig=TRUE, width=9.5, height=10, include=FALSE>>=
par(bty = "n")
par(mfrow = c(2, 2))
kall <- c(parsls[[1]][, "k"], parsls[[2]][, "k"])
hist(kall, xlab = "k", prob = TRUE, main = "Both chains", breaks = 0:22)
plot.new()
hist(parsls[[1]][, "k"], xlab = "k", prob = TRUE, main = "Chain 1", breaks = 0:22)
hist(parsls[[2]][, "k"], xlab = "k", prob = TRUE, main = "Chain 2", breaks = 0:22)
@ 
\begin{figure}[tb]
\caption{Histogram of sampled $k$.}
\label{fig6}.
\begin{center}
\includegraphics[height=5in, width=6.5in]{cgd1-fig6}
\end{center}
\end{figure}

Posterior densities of $\boldsymbol{\beta}$ parameters (based on the first chain only). The result
is shown in Figure~\ref{fig7}.
<<fig7, fig=TRUE, width=9.5, height=10, include=FALSE>>=
ch <- 1
par(bty = "n")
par(mfrow = c(3, 3))
for (i in 1:9){
   densplot(parsls[[ch]][,i], show.obs = FALSE, bty = "n")
   title(main = paste(attr(parsls[[ch]], "dimnames")[[2]][i], ", chain ", ch, sep = ""))
}
@ 
\begin{figure}[tb]
\caption{Posterior densities of $\boldsymbol{\beta}$ parameters.}
\label{fig7}.
\begin{center}
\includegraphics[height=6in, width=6.5in]{cgd1-fig7}
\end{center}
\end{figure}

Posterior densities of $k$, standard deviation $\sqrt{d}$ of the random intercept $b_i$,
mixture overall mean (intercept) and mixture overall standard deviation (error scale)
(based on the first chain).
The result is shown in Figure~\ref{fig8}.
<<fig8, fig=TRUE, width=9.5, height=10, include=FALSE>>=
ch <- 1
par(mfrow = c(2, 2))
densplot(parsls[[ch]][, "k"], show.obs = FALSE, bty = "n")
title(main = paste("k, chain", ch, sep = ""))
densplot(parsls[[ch]][, "sdb"], show.obs = FALSE, bty = "n")
title(main = paste("Std. Dev. of b, chain", ch, sep = ""))
densplot(parsls[[ch]][, "Intercept"], show.obs = FALSE, bty = "n")
title(main = paste("Intercept, chain ", ch, sep = ""))
densplot(parsls[[ch]][, "Scale"], show.obs = FALSE, bty = "n")
title(main = paste("Error Scale, chain ", ch, sep = ""))
@
\begin{figure}[tb]
\caption{Posterior densities of some other parameters.}
\label{fig8}.
\begin{center}
\includegraphics[height=6in, width=6.5in]{cgd1-fig8}
\end{center}
\end{figure}

\subsection{Autocorrelations}
Autocorrelation plots for some parameters in the first chain (see Figure~\ref{fig9} and \ref{fig10} for the results).
<<fig9, fig=TRUE, width=9.5, height=10, include=FALSE>>=
ch <- 1
par(bty = "n")
par(mfrow = c(3, 3))
autocorr.plot(parsls[[ch]][, 1:9], ask = FALSE, sub = paste("Chain ", ch, sep = ""))
@

<<fig10, fig=TRUE, width=9.5, height=10, include=FALSE>>=
par(bty = "n")
par(mfrow = c(2, 2))
plot.new()
autocorr.plot(parsls[[ch]][, 13], auto.layout = FALSE, ask = FALSE, sub = paste("Chain ", ch, sep = ""), main = "sdb")
autocorr.plot(parsls[[ch]][, 11:12], auto.layout = FALSE, ask = FALSE, sub = paste("Chain ", ch, sep = ""))
@

\begin{figure}[tb]
\caption{Autocorrelation plots.}
\label{fig9}.
\begin{center}
\includegraphics[height=6in, width=6.5in]{cgd1-fig9}
\end{center}
\end{figure}

\begin{figure}[tb]
\caption{Autocorrelation plots.}
\label{fig10}.
\begin{center}
\includegraphics[height=5in, width=6.5in]{cgd1-fig10}
\end{center}
\end{figure}

\subsection{Crosscorrelations}
Crosscorrelations (separately for each chain)
<<crosscorr>>=
croscor <- lapply(parsls, crosscorr)
croscor <- lapply(croscor, round, digits = 2)
names(croscor) <- paste("Chain ", 1:nchains, sep = "")
print(croscor)
@ 

\subsection{Gelman-Rubin convergence diagnostics}
Gelman-Rubin convergence diagnostics:
<<GelmanRubin>>=
gelm <- gelman.diag(parsls)
rownames(gelm$psrf) <- dimnames(parsls[[1]])[[2]]
print(gelm)
@ 

\subsection{Traceplots}
Traceplots for the first chain (see Figures~\ref{fig11}, \ref{fig12}, \ref{fig13} and \ref{fig14} for the result).
Observe that the function \texttt{densplot2} of the package \texttt{bayesSurv} is used.
<<fig11, fig=TRUE, width=9.5, height=10, include=FALSE>>=
ch <- 1
par(bty = "n")
par(mfrow = c(2, 2));  traceplot2(parsls[[ch]], chains = 1:3, sub = paste("Chain ", ch, sep = "")); 
@

<<fig12, fig=TRUE, width=9.5, height=10, include=FALSE>>=
par(bty = "n")
par(mfrow = c(2, 2));  traceplot2(parsls[[ch]], chains = 4:6, sub = paste("Chain ", ch, sep = "")); 
@

<<fig13, fig=TRUE, width=9.5, height=10, include=FALSE>>=
par(bty = "n")
par(mfrow = c(2, 2));  traceplot2(parsls[[ch]], chains = 7:9, sub = paste("Chain ", ch, sep = "")); 
@

<<fig14, fig=TRUE, width=9.5, height=10, include=FALSE>>=
par(bty = "n")
par(mfrow = c(2, 2))
traceplot2(parsls[[ch]], chains = 10, sub = paste("Chain ", ch, sep = ""))
traceplot2(parsls[[ch]], chains = 13, sub = paste("Chain ", ch, sep = ""))
traceplot2(parsls[[ch]], chains = 11:12, sub = paste("Chain ", ch, sep = ""))
@

\begin{figure}[tb]
\caption{Traceplots.}
\label{fig11}.
\begin{center}
\includegraphics[height=4in, width=6.5in]{cgd1-fig11}
\end{center}
\end{figure}

\begin{figure}[tb]
\caption{Traceplots.}
\label{fig12}.
\begin{center}
\includegraphics[height=4in, width=6.5in]{cgd1-fig12}
\end{center}
\end{figure}

\begin{figure}[tb]
\caption{Traceplots.}
\label{fig13}.
\begin{center}
\includegraphics[height=4in, width=6.5in]{cgd1-fig13}
\end{center}
\end{figure}
 
\begin{figure}[tb]
\caption{Traceplots.}
\label{fig14}.
\begin{center}
\includegraphics[height=4in, width=6.5in]{cgd1-fig14}
\end{center}
\end{figure}

\subsection{Performance of reversible jumps}
Check the performance of reversible jumps
(acceptance probabilities in split-combine move and in birth-death move):
<<performRevJump>>=
mh <- list() 
averMH <- list()
for (ch in 1:nchains){
  mh[[ch]] <- files2coda(files = c("MHinfo.sim"), start = 1, thin = 1, dir = get(paste("dirsim", ch, sep = "")))
  averMH[[ch]] <- apply(mh[[ch]][, c(1, 3)], 2, mean)
}  
for (ch in 1:nchains){
  cat("Chain ", ch, ":\n", sep = "")
  print(averMH[[ch]])
}  
@ 

Finally, we perform cleaning of generated files:
<<cleaning>>=
files1 <- dir("./cgdchain1")
files2 <- dir("./cgdchain2")
file.remove(paste("./cgdchain1/", files1, sep = ""))
file.remove(paste("./cgdchain2/", files2, sep = ""))
file.remove("cgdchain1")
file.remove("cgdchain2")
@ 

\end{document}
