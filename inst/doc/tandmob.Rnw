%\VignetteIndexEntry{Vignette describing the Signal Tandmobiel analysis from Komarek and Lesaffre (2004)}
\documentclass[a4paper]{article}

\usepackage{amsmath, amssymb, graphicx}

\setlength{\textheight}{9.8in}
\setlength{\textwidth}{6.23in}
\oddsidemargin=0mm
\evensidemargin=0mm
\topmargin=0mm
\hoffset=0mm
\voffset=-0.5in

\setlength{\parindent}{0pt}
\setlength{\parskip}{2mm}

\title{Signal Tandmobiel$^{\circledR}$ Data: Multivariate Survival Data  \\ -- an analysis using the package \texttt{bayesSurv}}
\author{Arno\v{s}t Kom\'{a}rek}

\begin{document}

\maketitle
In this document we describe the analysis of the Signal Tandmobiel$^{\circledR}$ data presented in 
Section~4.2 of Kom\'arek and Lesaffre (2004).

The model we will consider is the following:
\begin{align*}
\log(T_{i,l} - 5) &= \beta_1\,girl_{i,l} + \beta_2\,dmf_{i,l} + \beta_3\,girl_{i,l}dmf_{i,l} + \\
&\quad + \beta_4\,dmf_{i,l}lower4_{i,l} + \beta_5\,dmf_{i,l}upper5_{i,l} 
   + \beta_6\,dmf_{i,l}lower5_{i,l} + \\
&\quad + \beta_7\,girl_{i,l}lower4_{i,l} + \beta_8\,girl_{i,l}upper5_{i,l} 
   + \beta_9\,girl_{i,l}lower5_{i,l} + \\
&\quad + b_{i,1} + b_{i,2}lower4_{i,l} + b_{i,3}upper5_{i,l} + b_{i,4}lower5_{i,l} + \varepsilon_{i,l},
\end{align*}
where $l=1,\dots,8$ indexes 8 permanent teeth (14, 24, 15, 25, 34, 44, 35, 45) in the mouth. Further, $girl_{i,l}$ is equal to 1 if
the $i$th child is girl, $dmf_{i,l}$ is equal to 1 if the primary predecessor of the $l$th permanent tooth
of the $i$th child has a positive dmf score. Variables $lower4_{i,l}$, $upper5_{i,l}$ and $lower5_{i,l}$,
respectively are dummies for lower first premolars (teeth 34, 44), upper second premolars (teeth 15, 25)
and lower second premolars (teeth 35, 45), respectively.

Time variable $T_{i,l}$ gives the emergence time of the $l$th permanent tooth of the $i$th child in years.

Finally, for the random effect vector $\boldsymbol{b}_i$ it is assumed:
$E(b_{i,1}) = 0$, $E(b_{i,m})=\gamma_m$ $(m=2,3,4)$ and $\mbox{var}(\boldsymbol{b}_i) = \mathbb D$.

Dental therminology remark: upper jaw $=$ maxilla, lower jaw $=$ mandible. Teeth $10 + s$ are upper right teeth,
teeth $20 + s$ are upper left, teeth $30 + s$ are lower left and teeth $40 + s$ are lower right with $s = 1,\dots,8$.
Dental index of a~primary predecessor is obtained as $permanent + 40$ where $permanent$ is the index of the permanent tooth
(e.g. primary tooth 54 is predecessor of the permanent tooth 14).

%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Initial data manipulation}

Specify the directory where data are stored and load the \texttt{bayesSurv} package:
<<initop1>>=
library(bayesSurv)
wdir <- paste(getwd(), "/tandmob", sep = "")
@ 
Specify teeth we want to analyze (\texttt{dteeth} are corresponding deciduous teeth):
<<initop2>>=
pteeth <- c(14, 24, 34, 44, 15, 25, 35, 45)
dteeth <- pteeth + 40
nteeth <- length(pteeth)
@ 
Dummies for horizontally symmetric teeth (\texttt{upper4} = teeth 14 and 24, \texttt{lower4} = teeth 34 and 44,
\texttt{upper5} = teeth 15 and 25, \texttt{lower5} = teeth 35 and 45) further used in the analysis:
<<initop3>>=
upper4 <- c(1, 1, 0, 0, 0, 0, 0, 0)
lower4 <- c(0, 0, 1, 1, 0, 0, 0, 0)
upper5 <- c(0, 0, 0, 0, 1, 1, 0, 0)
lower5 <- c(0, 0, 0, 0, 0, 0, 1, 1)
@ 
Variables from the whole dataset that are needed or otherwise interesting
(\texttt{timevars} are variables that determine the interval where the emergence
was recorded, \texttt{dmfvars} give the caries status of corresponding
deciduous teeth):
<<initop4>>=
childvars <- c("IDNR", "GENDER", "GENDERNum", "DOB", "PROVINCE", "EDUC")
timevars <- paste(c("EBEG.", "EEND."), rep(pteeth, rep(2, nteeth)), sep="")
dmfvars <- paste("T", dteeth, ".DMF", sep="")
vars <- c(childvars, timevars, dmfvars)
print(vars)
@ 
Read the data (full dataset), take only interesting variables and change some names.
To see explanation of the variables take a look at the beginning of the file
\texttt{./tandmob/tandmob2.dat}.
<<initop5>>=
data <- read.table(paste(wdir, "/tandmob2.dat", sep = ""), skip = 65, header = TRUE, 
                 as.is = c(T, F, T, T, rep(F, 3), rep(T, 149)))
data <- data[, vars]
@ 
Change the name of \texttt{GENDERNum} variable:
<<init5b>>=
names(data)[names(data) == "GENDERNum"] <- "GIRL"
childvars[childvars == "GENDERNum"] <- "GIRL"
vars[vars == "GENDERNum"] <- "GIRL"
@ 
Take only children for who deciduous dmf score is available for all studied teeth:
<<initop6>>=
is.dmf <- !is.na(data$T54.DMF) & !is.na(data$T64.DMF) & !is.na(data$T74.DMF) & !is.na(data$T84.DMF) &
          !is.na(data$T55.DMF) & !is.na(data$T65.DMF) & !is.na(data$T75.DMF) & !is.na(data$T85.DMF) 
data <- data[is.dmf,]
@ 
Subtract 5.0 from all time variables (i.e. time 0 in the analyzes = 5 years of age):
<<initop7>>=
startage <- 5.0
data[, timevars] <- data[, timevars] - startage
@ 

Now we take only subsample of 50 boys and 50 girls (their id's are given in the file \texttt{IDsampled50.dat}).
In Kom\'arek and Lesaffre (2004) an analysis of the subsample of 500 boys and 500 girls is presented
(id's from \texttt{IDsampled500.dat}).
<<initop8>>=
nFromGender <- 50
ids <- read.table(paste(wdir, "/IDsampled", nFromGender, ".dat", sep=""), header=TRUE)[,1]
wanna <- match(data$IDNR, ids, nomatch=0)
wanna <- as.logical(wanna)
wanna[wanna > 1] <- TRUE
data <- data[wanna,]
@ 
Look at first few rows of the data:
<<initop5a>>=
print(data[1:10, ])
@ 
Now we have one row per child in the \texttt{data.frame} \texttt{data}.
We reformat the data such that there is one row per tooth and create 
factors to determine the tooth:
<<initop9>>=
nchild <- dim(data)[1]
longdata <- list()
for (i in 1:length(childvars)){
  longdata[[i]] <- rep(data[[childvars[i]]], nteeth)
}
names(longdata) <- childvars
longdata <- as.data.frame(longdata)
longdata$TOOTH <- as.factor(rep(pteeth, rep(nchild, nteeth)))
longdata$UPPER4 <- rep(upper4, rep(nchild, nteeth))
longdata$LOWER4 <- rep(lower4, rep(nchild, nteeth))
longdata$UPPER5 <- rep(upper5, rep(nchild, nteeth))
longdata$LOWER5 <- rep(lower5, rep(nchild, nteeth))
dmf <- numeric(); for (i in 1:nteeth) dmf <- c(dmf, data[[dmfvars[i]]])
ebeg <- numeric(); for (i in 1:nteeth) ebeg <- c(ebeg, data[[paste("EBEG.", pteeth[i], sep="")]])
eend <- numeric(); for (i in 1:nteeth) eend <- c(eend, data[[paste("EEND.", pteeth[i], sep="")]])
longdata$DMF <- dmf
longdata$EBEG <- ebeg
longdata$EEND <- eend
rm(list=c("dmf", "ebeg", "eend"))
longdata <- longdata[order(longdata$IDNR), ]
@
Look at first few rows (2 children) of reformatted data:
<<initop10>>=   
print(longdata[1:16,])
@ 


%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Finding reasonable values for hyperparameters and initial values}
We fit the log-normal AFT model without any random effects to get initial values
for model parameters and reasonable values for hyperparameters:
<<initval1>>=
ifit <- survreg(Surv(EBEG, EEND, type="interval2") ~ GIRL*DMF + (DMF+GIRL)*(LOWER4 + UPPER5 + LOWER5),
                 dist = "lognormal", data = longdata)
summary(ifit)
@ 


%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Specification of priors}
To specify correctly the prior hyperparameters for $\boldsymbol{\beta}$ and $\boldsymbol{\gamma}$ 
parameters we have to know 
how the covariates are sorted in the design matrix. Normally, the same order should be
used as in the \texttt{formula} specification. However, one never knows\dots

The following command returns the design matrix and we look at first few rows
to see how are the covariates sorted in the columns. We also define the variable
\texttt{nregres} (number of covariates). The same model \texttt{formula} is used
as in the future function call.
<<prior1>>=
X <- bayessurvreg1(Surv(EBEG, EEND, type="interval2") ~ GIRL*DMF + (DMF+GIRL)*(LOWER4 + UPPER5 + LOWER5) + cluster(IDNR),
                   random =~ LOWER4 + UPPER5 + LOWER5, data = longdata[1:80,], onlyX = TRUE)
@ 
Print first few lines of X to see how \texttt{beta}s are sorted. Remember that both $\boldsymbol{\beta}$
and $\boldsymbol{\gamma}$ parameters from Kom\'arek and Lesaffre (2004) are put into one
long vector \texttt{beta} in the {\scshape R} functions.
<<prior2>>=
print(X[1:5,])
nregres <- dim(X)[2]
nobs <- dim(longdata)[1]
@ 
So we see that \texttt{beta[1:12]} = $(\beta(girl),\: \beta(dmf),\: \gamma(lower4),\: \gamma(upper5),\: \gamma(lower5),\: \beta(girl:dmf),\:
\beta(dmf:lower4),\: \beta(dmf:upper5),\: \beta(dmf:lower5),\: \beta(girl:lower4),\: \beta(girl:upper5),\: \beta(girl:lower5))'$.

Notice that the random effect vector is now 4-dimensional, i.e. $\boldsymbol{b}_i = (b_{i,1}, b_{i,2}, b_{i,3}, b_{i,4})'$
and $E(b_{i,1}) = 0$, $E(b_{i,2}) = \gamma(lower4)$, $E(b_{i,3}) = \gamma(upper5)$, $E(b_{i,4}) = \gamma(lower5)$.

%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Priors for the mixture}
<<priormix1>>=
prior <- list()
@ 
Prior for the number of mixture components $k$ will be truncated Poisson($\lambda$, $k_{max}$) with $k_{max}=30$
and $\lambda = 5$. Alternative prior distribution would be uniform specified by 
\begin{verbatim}
prior$k.prior = ``uniform''
\end{verbatim}
<<priormix2>>=
prior$kmax <- 30
prior$k.prior <- "poisson"
prior$poisson.k <- 5
@ 
Prior for mixture weights $w_1,\dots,w_k$ will be Dirichlet($\delta,\dots,\delta$) with $\delta = 1$.
<<priormix3>>=
prior$dirichlet.w <- 1
@ 
Prior for mixture means $\mu_1,\dots,\mu_k$ will be N($\xi, \kappa$) with $\xi = 1.8$ 
(taken from \texttt{survreg(dist = "lognormal")} fit (approx intercept)) and $\kappa = 0.75^2 \approx (3\times 0.25)^2$
(0.25 was approximately estimated scale parameter by \texttt{survreg}).
<<priormix4>>=
prior$mean.mu <- 1.8
prior$var.mu <- 0.75^2
@ 
Prior for mixture inverse-variances $\sigma^{-2}_1,\dots,\sigma_k^{-2}$ will be Gamma$(\zeta, \eta)$
and prior for $\eta$ will be Gamma$(g,h)$, with $\zeta = 2.0$, $g=0.2$ and $h=0.1$. 
<<priormix5>>=
prior$shape.invsig2 <- 2.0
prior$shape.hyper.invsig2 <- 0.2
prior$rate.hyper.invsig2 <- 0.1
@ 
Probabilities of the split move (given current value of $k$) will be always $0.5$ except when $k=1$
or $k=k_{max}$.
<<priormix6>>=
prior$pi.split <- c(1, rep(0.5, prior$kmax - 2), 0)
@ 
Probabilities of the birth move (given current value of $k$) will be always $0.5$ except when $k=1$
or $k=k_{max}$.
<<priormix7>>=
prior$pi.birth <- c(1, rep(0.5, prior$kmax - 2), 0)
@ 
The last component of the \texttt{list} \texttt{prior} should be always set to 
\texttt{FALSE}. Its value equal to \texttt{TRUE} served only for some
exploratory purposes of the author.
<<priormix8>>=
prior$Eb0.depend.mix <- FALSE
@ 
Look how it looks like:
<<priormix9>>=
print(prior)
@ 

%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Priors for regression parameters $\boldsymbol{\beta}$ and means of random effects $\boldsymbol{\gamma}$}
In this section we specify the prior hyperparameters for
\texttt{beta[1:12]} $=$ $(\beta(girl),\: \beta(dmf),\: \gamma(lower4),\:$
$\gamma(upper5),\:$ $\gamma(lower5),\:$ $\beta(girl:dmf),\:$
$\beta(dmf:lower4),\:$ $\beta(dmf:upper5),\:$ $\beta(dmf:lower5),\:$ $\beta(girl:lower4),\:$ 
$\beta(girl:upper5),\:$ $\beta(girl:lower5))'$
and the way these parameters will be updated. In other words, we define a \texttt{list} with all the information needed.
<<priorbeta1>>=
prior.beta <- list()
@ 
Here we specify prior means (all will be zero) and prior variances (all will be 100) for the \texttt{beta} parameters.
<<priorbeta2>>=
prior.beta$mean.prior <- rep(0, nregres)
prior.beta$var.prior <- rep(1e2, nregres)
@ 
Further, we do not have to do anything, i.e. default way to update the \texttt{beta} parameters will be used.
That is by the Gibbs move in two blocks (all fixed effects $\boldsymbol{\beta}$ in one block and means $\boldsymbol{\gamma}$
of all random effects in the second block).

Look how the list looks like:
<<priorbeta3>>=
print(prior.beta)
@ 

%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Prior specification for the random effects $\boldsymbol{b}_i$ related parameters}
Now, we have to specify the prior for the variance matrix $\mathbb D$ of the random effect vector
$\boldsymbol{b}_i$. Again, we define a \texttt{list} with all the information:
<<priorb1>>=
prior.b <- list()
@ 
We use an inverse-Wishart prior for $\mathbb D$ with $\tau = 4$ degrees of freedom 
and a~scale matrix $\mathbb S$ equal to
\begin{displaymath}
\mathbb S = 0.002 \times \begin{pmatrix} 1&0&0&0 \\ 0&1&0&0 \\ 0&0&1&0 \\ 0&0&0&1 \\\end{pmatrix}.
\end{displaymath}
Observe that only the lower triangle of $\mathbb S$ is given to \texttt{prior\$scale.D}.
<<priorb2>>=
prior.b$df.D <- 4
prior.b$scale.D <- 0.002*c(1, 0, 0, 0, 1, 0, 0, 1, 0, 1)
prior.b$prior.D <- "inv.wishart"
@ 
Finally, we specify how the individual random effects will be updated (using the Gibbs move):
<<priorb3>>=
prior.b$type.upd <- "gibbs"
@ 
Look how the list looks like:
<<priorb4>>=
print(prior.b)
@ 

%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Parameters to perform reversible jumps}
<<revjump1>>=
prop.revjump <- list()
@ 
Type of the algorithm:
<<revjump2>>=
prop.revjump$algorithm <- "correlated.av"
@ 
Parameters of a moody ring ($\epsilon$, $delta$, see paper Brooks et al. (2003) for details).
Remember, $\epsilon$ = time dependence, $\delta$ = component dependence.
<<revjump3>>=
prop.revjump$moody.ring <- c(0.1, 0.05)
@ 
Transformation of a canonical seed for split-combine move:
<<revjump4>>=
prop.revjump$transform.split.combine <- "brooks"
prop.revjump$transform.split.combine.parms <- c(2, 2, 2, 2, 1, 1)
@ 
Transformation of a canonical seed for birth-death move:
<<revjump5>>=
prop.revjump$transform.birth.death <- "richardson.green"
@ 
Look how it looks like:
<<revjump6>>=
print(prop.revjump)
@ 


%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Specification of initial values for the MCMC}
We give two sets of initial values to run two chains. Undefined initials 
are sampled automatically by the program.

\subsection{Initials for chain 1}
<<init11>>=
init1 <- list()
@ 
Iteration number of the nulth iteration:
<<init12>>=
init1$iter <- 0
@ 
Initial mixture (from \texttt{survreg(dist = "lognormal")}). It will have one component
with $w_1 = 1$, $\mu_1 = 1.8$ and $\sigma_1^2 = 0.25^2$.
<<init13>>=
init1$mixture <- c(1,
                   1, rep(0, prior$kmax - 1),
                   1.8, rep(0, prior$kmax - 1),
                   0.25^2, rep(0, prior$kmax - 1))
@ 
Initial regression parameters $\boldsymbol{\beta}$ and means of random effects
$\boldsymbol{\gamma}$ (from \texttt{survreg(dist = "lognormal")}):
<<init14>>=
init1$beta <- c(-0.09, -0.11, -0.01, 0.16, 0.17, 0.05, 0.02, 0.01, 0.03, -0.02, 0.01, 0)  
@ 
Initial covariance matrix $\mathbb D$ of the random effects will be identity matrix
(only its lower triangle)
<<init15>>=
init1$D <- c(1, 0, 0, 0, 1, 0, 0, 1, 0, 1)
@ 
Initial values of individual random effects for each child:
<<init16>>=
b0 <- rep(0, nchild)
b1 <- rnorm(nchild, 0, 0.3)
b2 <- rnorm(nchild, 0.16, 0.3)
b3 <- rnorm(nchild, 0.16, 0.3)
init1$b <- as.numeric(rbind(b0, b1, b2, b3))
@ 
Initial (augmented) log(event) times -- let the program sample them:
<<init17>>=
init1$y <- NULL
@ 
Initial component pertinence of the observations to the mixture (all observations
belong to the first component):
<<init18>>=
init1$r <- rep(1, nobs)
@ 
Initial value of a hyperparameter $\eta$ (sample it from a prior distribution):
<<init19>>=
init1$otherp <- rgamma(1, shape = prior$shape.hyper.invsig2, rate = prior$rate.hyper.invsig2)
@ 
Initial values of canonical variables for reversible move (sample it from a uniform distribution):
<<init110>>=
init1$u <- c(runif(1), 0, 0, runif(3*(prior$kmax - 1)))
@ 

\subsection{Initials for chain 2}
<<init21>>=
init2 <- list()
@ 
Iteration number of the nulth iteration:
<<init22>>=
init2$iter <- 0
@ 
Initial mixture. It will have one component
with $w_1 = 1$, $\mu_1 = 1.7$ and $\sigma_1^2 = 0.2^2$.
<<init23>>=
init2$mixture <- c(1, 
                   1, rep(0, prior$kmax - 1),
                   1.7, rep(0, prior$kmax - 1),
                   0.20^2, rep(0, prior$kmax - 1))
@ 
Initial regression parameters $\boldsymbol{\beta}$ and means of random effects
$\boldsymbol{\gamma}$ (all zeros):
<<init24>>=
init2$beta <- rep(0, nregres)
@ 
Initial covariance matrix $\mathbb D$ of the random effects. Now we take such 
matrix $\mathbb D$ that var$(b_{i,m}) = 0.01$ $(m=1,2,3,4)$ and 
corr$(b_{i,m}, b_{i,s}) = 0.2$ $(m\neq s = 1,2,3,4)$.
<<init25>>=
varb <- c(0.01, 0.01, 0.01, 0.01)
corb <- c(0.2, 0.2, 0.2,  0.2, 0.2,  0.2)
Corb <- diag(4)
Corb[lower.tri(Corb, diag=FALSE)] <- corb
Corb[upper.tri(Corb, diag=FALSE)] <- t(Corb)[upper.tri(t(Corb), diag=FALSE)]
Covb <- diag(sqrt(varb)) %*% Corb %*% diag(sqrt(varb))
init2$D <- Covb[lower.tri(Covb, diag=TRUE)]
@ 
Initial values of individual random effects for each child:
<<init26>>=
b0 <- rnorm(nchild, 0, sqrt(init2$D[1])) 
b1 <- rnorm(nchild, 0, sqrt(init2$D[5]))
b2 <- rnorm(nchild, 0.16, sqrt(init2$D[8])) 
b3 <- rnorm(nchild, 0.16, sqrt(init2$D[10]))
init2$b <- as.numeric(rbind(b0, b1, b2, b3))
@ 
Initial (augmented) log(event) times -- let the program sample them:
<<init27>>=
init2$y <- NULL
@ 
Initial component pertinence of the observations to the mixture (all observations
belong to the first component):
<<init28>>=
init2$r <- rep(1, nobs)
@ 
Initial value of a hyperparameter $\eta$ (sample it from a prior distribution):
<<init29>>=
init2$otherp <- rgamma(1, shape = prior$shape.hyper.invsig2, rate = prior$rate.hyper.invsig2)
@ 
Initial values of canonical variables for reversible move (sample it from a uniform distribution):
<<init210>>=
init2$u <- c(runif(1), 0, 0, runif(3*(prior$kmax - 1)))
@ 


%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Running the MCMC simulation}
Now we are ready to run the MCMC to sample from the posterior distribution.

Here we define which quantities that are not neccessarily needed for the inference
will be stored.
<<run1>>=
store <- list(y = FALSE, r = FALSE, u = FALSE, b = FALSE, MHb = FALSE, regresres = FALSE)
@ 
How long simulation we want to run? For illustration purposes, only limited simulation
is specified here. 
<<run2>>=
nsimul <- list(niter = 1000, nthin = 3, nburn = 500, nwrite = 500)
@ 
For the analysis presented in Kom\'arek and Lesaffre (2004) we used
\begin{verbatim}
> nsimul <- list(niter = 15000, nthin = 3, nburn = 1500, nnoadapt = 0, nwrite = 1000)
\end{verbatim}
which performed 3$\times$1\,500 iterations of burn-in and additionally 3$\times$13\,500 iterations from which 
each 3rd value was stored. Further, after cumulating 1\,000 sampled values, these were stored on a disk.

Define directories where first and second chain will be stored (create them first):
<<run3>>=
dir.create("tandchain1")
dir.create("tandchain2")
dirsim <- character()
dirsim[1] <- paste(getwd(), "/tandchain1", sep = "")
dirsim[2] <- paste(getwd(), "/tandchain2", sep = "")
@ 
Run the simulation for the first and the second chain:
<<runChain1, term=FALSE>>=
sim1 <- bayessurvreg1(Surv(EBEG, EEND, type="interval2") ~ GIRL*DMF + (DMF+GIRL)*(LOWER4 + UPPER5 + LOWER5) + cluster(IDNR),
                random=~ LOWER4 + UPPER5 + LOWER5, data=longdata, dir=dirsim[1], nsimul=nsimul,
                prior=prior, init=init1, prop.revjump=prop.revjump, prior.beta=prior.beta, prior.b=prior.b,
                store=store)
<<runChain2, term=FALSE>>=
sim2 <- bayessurvreg1(Surv(EBEG, EEND, type="interval2") ~ GIRL*DMF + (DMF+GIRL)*(LOWER4 + UPPER5 + LOWER5) + cluster(IDNR),
                random=~ LOWER4 + UPPER5 + LOWER5, data=longdata, dir=dirsim[2], nsimul=nsimul,
                prior=prior, init=init2, prop.revjump=prop.revjump, prior.beta=prior.beta, prior.b=prior.b,
                store=store)
@ 

%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Running additional MCMC simulation to compute predictive quantities}
First we have to define covariate values for which we want to do a prediction.
These will be all combinations of boy/girl $\times$ dmf$>$0/dmf$=$0
$\times$ upper4/lower4/upper5/lower5:
<<pred1>>=
newIDNR    = c(1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4)
newGIRL    = c(0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1)
newUPPER4  = c(1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0)
newLOWER4  = c(0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0)
newUPPER5  = c(0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0)
newLOWER5  = c(0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1)
newDMF     = c(0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1)
newEBEG    = rep(1, 16)
newEEND    = rep(NA, 16)                      
preddata <- data.frame(IDNR    = newIDNR,
                       GIRL    = newGIRL,
                       UPPER4  = newUPPER4,
                       LOWER4  = newLOWER4,
                       UPPER5  = newUPPER5,
                       LOWER5  = newLOWER5,
                       DMF     = newDMF,
                       EBEG    = newEBEG,
                       EEND    = newEEND)              
print(preddata)
@ 
Observe that variables \texttt{EBEG} and \texttt{EEND} may contain whatever (under the condition
that the values are acceptable for \texttt{Surv}). 

Further, we specify what we want to predict (with this, survivor function and hazard function).
Also, specify whether sampled quantities should be stored, otherwise, only quantiles and predictive means
are computed (which usually suffice).
<<pred2>>=
predict <- list(Et = TRUE, t = FALSE, Surv = TRUE, hazard = TRUE, cum.hazard = FALSE)
store <- list(Et = FALSE, t = FALSE, Surv = FALSE, hazard = FALSE, cum.hazard = FALSE)
@ 
Grid of values in which predictive survivor and hazard curves should be computed.
Observe that this grid takes into account the fact we shifted the response by $5$ years
in the model. Here we return back to the original time scale, i.e. we wish to see
predictive curves between 6.5 and 13 years of age.
<<pred3>>=
grid <- seq(6.5, 13, by=0.1)
@ 
How many MCMC iterations we want to perform (\texttt{niter} should be $\leq$ length of already sampled chain)
and how often should sampled quantities be written to disk
<<pred4>>=
nsimul.pred <- list(niter = nsimul$niter-nsimul$nburn, nthin = 1, nwrite = nsimul$niter-nsimul$nburn)
@ 
Run MCMC simulation to sample from the predictive distribution (only chain 1 will be used here).
Observe how we used parameter \texttt{time0} in the function call to specify that the response
was shifted in the model by \texttt{startage} $=$ 5.
<<runPredict, term=FALSE>>=
simulp1 <- predictive(Surv(EBEG, EEND, type="interval2") ~ GIRL*DMF + (DMF+GIRL)*(LOWER4 + UPPER5 + LOWER5) + cluster(IDNR),
                     random=~ LOWER4 + UPPER5 + LOWER5, time0=startage,
                     data = preddata, dir = dirsim[1], nsimul = nsimul.pred, predict = predict, store = store, grid = grid,
                     type = "mixture")
@ 
In a directory \texttt{./tandchain1} few new files should appear: 
\begin{itemize}
\item \texttt{quantS1.sim} -- \texttt{quantS8.sim};
\item \texttt{quanthazard1.sim} -- \texttt{quanthazard8.sim};
\item \texttt{quantET.sim}.
\end{itemize}
Files \texttt{quantS*.sim} and \texttt{quanthazard*.sim} contain pointwise (evaluated at the grid specified above)
posterior predictive quantiles and means of the survivor and hazard function
for each combination of covariates specified in \texttt{preddata}.
File \texttt{quantET.sim} contains posterior predictive quantiles and mean for expected
survivor time of each combination of covariates.
Note that
\begin{enumerate}
\item There is one file per survivor/hazard function and per covariate combination.
Indeces of these files (1, ..., 8) correspond to rows of \texttt{preddata}.
Structure of these files is following
\begin{center}
\begin{tabular}{rcl}
 1st row & $=$ & grid values \\
 2nd row & $=$ & post. predictive 0\% quantile (minimum) \\
 3rd row & $=$ & post. predictive 2.5\% quantile \\
 4th row & $=$ & post. predictive 50\% quantile (median) \\
 5th row & $=$ & post. predictive 97.5\% quantile \\
 6th row & $=$ & post. predictive 100\% quantile (maximum) \\
 last row & $=$ & post. predictive mean \\
\end{tabular}
\end{center}
\item There is only one file for posterior predictive expected survivor times
and all combinations of covariates (\texttt{quantET.sim}).
Structure of this file is following:
\begin{center}
\begin{tabular}{rcl}
 1st row & $=$ & character labels ET1 - ET8  \\
          && indicating that each column corresponds  \\
          && to one covariate combination \\
 remaining rows & $=$ & same as for \texttt{quantS*.sim} or \texttt{quanthazard*.sim} \\
\end{tabular}
\end{center}
\end{enumerate}
\bigskip
You might specify also other quantiles (parameter \texttt{quantile} in function \texttt{predictive}) to be computed.
Posterior predictive mean is always computed and stored on the last row.


%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Drawing of posterior predictive emergence curves}
%<<tempdir, echo=FALSE>>=
%dirsim[1] <- paste(getwd(), "/longtandmobChain1", sep = "")
%dirsim[2] <- paste(getwd(), "/longtandmobChain2", sep = "")
@ 
Here we draw predictive emergence curves (cumulative distribution functions),
separately for each pair of horizontally symmetric teeth (14+24, 34+44, 15+25, 35+45),
for boys and girls and finally depending on the $dmf$ score of the primary
predecessor. We use simulated predictive curves based on the first chain.
See Figure~\ref{emerc1} for the result.
<<emerc1, fig=TRUE, include=FALSE, width=8, height=10>>=
ch <- 1
line <- numeric(13); line[1] <- 1; line[5] <- 2; line[9] <- 1; line[13] <- 2
col <- character(13); col[1] <- "blue"; col[5] <- "blue"; col[9] <- "red"; col[13] <- "red"
title <- c("Maxilla 4", "Mandible 4", "Maxilla 5", "Mandible 5")
lwd <- 2
xlim <- c(7, 12)
par(mfrow = c(2, 2))
for (i in 1:4){
  for(j in c(1,5,9,13)){
    gridS <- scan(paste(dirsim[ch], "/quantS", (i-1)+j, ".sim", sep = ""), nlines = 1) 
    Sfun <- read.table(paste(dirsim[ch], "/quantS", (i-1)+j, ".sim", sep = ""), header = TRUE)
    rownames(Sfun) <- c("0%", "2.5%", "50%", "97.5%", "100%", "mean")
    if (j == 1) plot(gridS, 1-Sfun["mean", ], type="l", lty=line[1], ylim=c(0, 1), xlab="Age", ylab="Emergence", bty="n", lwd=lwd, col=col[1], xlim=xlim)
    else        lines(gridS, 1-Sfun["mean", ], lty=line[j], lwd=lwd, col=col[j])
    legend(7, 1, legend = c("Girl, dmf>0", "Girl, sound", "Boy, dmf>0", "Boy, sound"), lty=line[c(13,9,5,1)], col=col[c(13,9,5,1)], lwd=lwd, bty = "n")
  }
  title(main = title[i])
}  
@ 
\begin{figure}[tbh]
  \centering  
  \caption{Predictive emergence curves.}
  \label{emerc1}
  \includegraphics[width=6.5in, height=5in]{tandmob-emerc1}
\end{figure}  


%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Summary statistics}
Check how many chains we have
<<summ1>>=
nchains <- length(dirsim)
print(nchains)
@ 
Read sampled $\mathbb D$ matrix and perform some transformation on it.
Data frames in \texttt{covb} will store chains for standard deviations
of $b_{i,1}, b_{i,2}, b_{i,3}, b_{i,4}$ and correlations among
$b$'s. Further, to see an inter-teeth relationship we define
$d_{i,1} = b_{i,1}$, $d_{i,2} = b_{i,1} + b_{i,2}$,
$d_{i,3} = b_{i,1} + b_{i,3}$ and $d_{i,4} = b_{i,1} + b_{i,4}$,
i.e. each $d$ is actually the child-tooth-specific (apart the horizontal symmetry)
shift of log-emergence time ($d_{i,1}$ for teeth 14, 24, $d_{i,2}$ for teeth 34, 44,
$d_{i,3}$ for teeth 15, 25 and $d_{i,4}$ for teeth 35, 45).
Date frames in \texttt{covt} then store chains for 
standard deviations
of $d_{i,1}, d_{i,2}, d_{i,3}, d_{i,4}$ and correlations among
$d$'s.
<<summ2>>=
covb <- list()
covt <- list()
for (ch in 1:nchains){
  dd <- read.table(paste(dirsim[ch], "/D.sim", sep=""), header=TRUE)

  varb <- cbind(dd$D.1.1, dd$D.2.2, dd$D.3.3, dd$D.4.4)
  sdb <- sqrt(varb)
  corb12 <- dd$D.2.1/sqrt(dd$D.1.1*dd$D.2.2)
  corb13 <- dd$D.3.1/sqrt(dd$D.1.1*dd$D.3.3)
  corb14 <- dd$D.4.1/sqrt(dd$D.1.1*dd$D.4.4)
  corb23 <- dd$D.3.2/sqrt(dd$D.2.2*dd$D.3.3)
  corb24 <- dd$D.4.2/sqrt(dd$D.2.2*dd$D.4.4)
  corb34 <- dd$D.4.3/sqrt(dd$D.3.3*dd$D.4.4)
  covb[[ch]] <- data.frame(sdb, corb12, corb13, corb14, corb23, corb24, corb34)
  colnames(covb[[ch]]) <- c(paste("sd", 1:4, sep=""), paste("cor", c(12, 13, 14, 23, 24, 34), sep=""))
  
  sdt1 <- sqrt(dd$D.1.1)
  sdt2 <- sqrt(dd$D.1.1 + dd$D.2.2 + 2*dd$D.2.1)
  sdt3 <- sqrt(dd$D.1.1 + dd$D.3.3 + 2*dd$D.3.1)
  sdt4 <- sqrt(dd$D.1.1 + dd$D.4.4 + 2*dd$D.4.1)
  cort12 <- (dd$D.1.1 + dd$D.2.1)/(sdt1*sdt2)
  cort13 <- (dd$D.1.1 + dd$D.3.1)/(sdt1*sdt3)
  cort14 <- (dd$D.1.1 + dd$D.4.1)/(sdt1*sdt4)
  cort23 <- (dd$D.1.1 + dd$D.2.1 + dd$D.3.1 + dd$D.3.2)/(sdt2*sdt3)
  cort24 <- (dd$D.1.1 + dd$D.2.1 + dd$D.4.1 + dd$D.4.2)/(sdt2*sdt4)
  cort34 <- (dd$D.1.1 + dd$D.3.1 + dd$D.4.1 + dd$D.4.3)/(sdt3*sdt4)
  covt[[ch]] <- data.frame(sdt1, sdt2, sdt3, sdt4, cort12, cort13, cort14, cort23, cort24, cort34)  
}
@ 
Read sampled $\boldsymbol{\beta}$ and $\boldsymbol{\gamma}$ parameters:
<<summ3>>=
beta <- list()
for(ch in 1:nchains){
  beta[[ch]] <- read.table(paste(dirsim[ch], "/beta.sim", sep=""), header=TRUE)
}  
@ 
Read sampled numbers of mixture components $k$ and mixture overall mean (intercept)
and mixture overall standard deviation (scale):
<<summ4>>=
mixture <- list()
for(ch in 1:nchains){
  mixture[[ch]] <- read.table(paste(dirsim[ch], "/mixmoment.sim", sep=""), header=TRUE)
}  
@ 
Create \texttt{CODA} \texttt{mcmc} objects from sampled chains:
<<summ5>>=
library(coda)
mcovb <- list(); mcovt <- list(); mbeta <- list(); mmixture <- list()
for (ch in 1:nchains){
  mcovb[[ch]] <- files2coda(data.frames="covb", thin=1, chain=ch)
  mcovt[[ch]] <- files2coda(data.frames="covt", thin=1, chain=ch)
  mbeta[[ch]] <- files2coda(data.frames="beta", thin=1, chain=ch)  
  mmixture[[ch]] <- files2coda(data.frames="mixture", thin=1, chain=ch)  
}
mcovb <- mcmc.list(mcovb[[1]], mcovb[[2]])
mcovt <- mcmc.list(mcovt[[1]], mcovt[[2]])
mbeta <- mcmc.list(mbeta[[1]], mbeta[[2]])
mmixture <- mcmc.list(mmixture[[1]], mmixture[[2]])
@ 

Compute some summary statistics:
<<summ6>>=
quant <- c(0, 0.025, 0.5, 0.75, 0.975, 1)
qnames <- paste(quant*100, "\\%", sep = "")

meancovb <- apply(rbind(covb[[1]], covb[[2]]), 2, mean)
meancovt <- apply(rbind(covt[[1]], covt[[2]]), 2, mean)
meanbeta <- apply(rbind(beta[[1]], beta[[2]]), 2, mean)
meanmixture <- apply(rbind(mixture[[1]], mixture[[2]]), 2, mean)

quantcovb <- apply(rbind(covb[[1]], covb[[2]]), 2, quantile, probs=quant)
quantcovt <- apply(rbind(covt[[1]], covt[[2]]), 2, quantile, probs=quant)
quantbeta <- apply(rbind(beta[[1]], beta[[2]]), 2, quantile, probs=quant)
quantmixture <- apply(rbind(mixture[[1]], mixture[[2]]), 2, quantile, probs=quant)

sumcovb <- rbind(meancovb, quantcovb[c("50%", "2.5%", "97.5%"), ]); rownames(sumcovb)[1] <- "Mean"
sumcovt <- rbind(meancovt, quantcovt[c("50%", "2.5%", "97.5%"), ]); rownames(sumcovt)[1] <- "Mean"
sumbeta <- rbind(meanbeta, quantbeta[c("50%", "2.5%", "97.5%"), ]); rownames(sumbeta)[1] <- "Mean"
summixture <- rbind(meanmixture, quantmixture[c("50%", "2.5%", "97.5%"), ]); rownames(summixture)[1] <- "Mean"

sumwant <- cbind(sumcovt, sumbeta, summixture)
print(sumwant)
@ 
In the previous table, \texttt{sdt1} $=$ $\sqrt{\mbox{var}(d_{i,1})}$,
\texttt{sdt2} $=$ $\sqrt{\mbox{var}(d_{i,2})}$, \texttt{sdt3} $=$ $\sqrt{\mbox{var}(d_{i,3})}$, \texttt{sdt4} $=$ $\sqrt{\mbox{var}(d_{i,4})}$,
\texttt{cort12} $=$ $\mbox{corr}(d_{i,1}, d_{i,2})$, \dots,\texttt{cort34} $=$ $\mbox{corr}(d_{i,3}, d_{i,4})$.

Bayesian $p$-values for regression parameters:
<<summ7>>=
regres <- list(); pval <- numeric(9)
for (i in 1:12){
  regres[[i]] <- c(beta[[1]][,i], beta[[2]][,i])
  M <- length(regres[[i]])
  p1 <- sum(regres[[i]] < 0)/M
  p2 <- sum(regres[[i]] > 0)/M
  pval[[i]] <- 2*min(p1, p2)
  names(pval)[i] <- colnames(beta[[1]])[i]
}  
pval <- round(pval, 3)
rm(list="regres")
print(pval)
@ 

Bayesian $p$-values for effect of dmf for different teeth (maxillary 4, mandibular 4, maxillary 5, mandibular 5) 
and different genders ($p$-values for proper combinations of $\beta$ and $\gamma$ parameters):
<<summ8>>=
betaall <- rbind(beta[[1]], beta[[2]])
dmfeff <- data.frame(
            girl.max4 = betaall$DMF + betaall$GIRL.DMF,
            boy.max4 = betaall$DMF,
            girl.max5 = betaall$DMF + betaall$GIRL.DMF + betaall$DMF.UPPER5,
            boy.max5 = betaall$DMF + betaall$DMF.UPPER5,                     
            girl.man4 = betaall$DMF + betaall$GIRL.DMF + betaall$DMF.LOWER4,
            boy.man4 = betaall$DMF + betaall$DMF.LOWER4,
            girl.man5 = betaall$DMF + betaall$GIRL.DMF + betaall$DMF.LOWER5,
            boy.man5 = betaall$DMF + betaall$DMF.LOWER5                     
          )                     
meandmfeff <- apply(dmfeff, 2, mean)
quantdmfeff <- apply(dmfeff, 2, quantile, probs=quant)
sumdmfeff <- rbind(meandmfeff, quantdmfeff[c("50%", "2.5%", "97.5%"), ]); rownames(sumdmfeff)[1] <- "Mean"
dmfpval <- numeric()
for (i in 1:8){
  M <- length(dmfeff[[i]])
  p1 <- sum(dmfeff[[i]] < 0)/M
  p2 <- sum(dmfeff[[i]] > 0)/M
  dmfpval[[i]] <- 2*min(p1, p2)
  names(dmfpval)[i] <- colnames(dmfeff)[i]
}
print(sumdmfeff)
print(dmfpval)
@ 


%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Selected convergence diagnostics and further summary using the \texttt{coda} package}
We show some basic convergence diagnostics and some additional summary based on the first chain.

Posterior densities for regression parameters $\boldsymbol{\beta}$, means of random effects
$\boldsymbol{\gamma}$, standard deviations and correlations of transformed random effects
$\boldsymbol{d}_i$ and overall mixture mean (intercept), mixture standard deviation (scale)
and number of mixture components. See Figures~\ref{dens1}, \ref{dens2}, \ref{dens3} for the results.
<<dens1, fig=TRUE, width=8, height=10, include=FALSE>>=
ch <- 1
par(mfrow=c(3, 4)); for(i in 1:12){ densplot2(mcmc(beta[[ch]][,i]), main=colnames(beta[[ch]])[i]) }
<<dens2, fig=TRUE, width=8, height=10, include=FALSE>>=
par(mfrow=c(3, 4)); for(i in 1:10){ densplot2(mcmc(covt[[ch]][,i]), main=colnames(covt[[ch]])[i]) }
<<dens3, fig=TRUE, width=8, height=10, include=FALSE>>=
par(mfrow=c(2, 2)); for(i in 1:3){ densplot2(mcmc(mixture[[ch]][,i]), main=colnames(mixture[[ch]])[i]) }
@ 
\begin{figure}[tbh]
  \centering  
  \caption{Posterior distribution of $\boldsymbol{\beta}$ and $\boldsymbol{\gamma}$ parameters.}
  \label{dens1}
  \includegraphics[width=6.5in, height=8in]{tandmob-dens1}
\end{figure}  

\begin{figure}[tbh]
  \centering  
  \caption{Posterior distribution of standard deviations and correlations of transformed random effects $\boldsymbol{d}_i$.}
  \label{dens2}
  \includegraphics[width=6.5in, height=8in]{tandmob-dens2}
\end{figure}  

\begin{figure}[tbh]
  \centering  
  \caption{Posterior distribution for mixture related parameters.}
  \label{dens3}
  \includegraphics[width=6.5in, height=5in]{tandmob-dens3}
\end{figure}  

Autocorrelation plots for regression parameters $\boldsymbol{\beta}$, means of random effects
$\boldsymbol{\gamma}$, standard deviations and correlations of transformed random effects
$\boldsymbol{d}_i$ and overall mixture mean (intercept), mixture standard deviation (scale)
and number of mixture components. See Figures~\ref{acor1}, \ref{acor2}, \ref{acor3} for the results.
<<acor1, fig=TRUE, width=8, height=10, include=FALSE>>=
par(mfrow=c(3, 4)); autocorr.plot(mcmc(beta[[ch]]), auto.layout=FALSE, ask=FALSE, bty="n")
<<acor2, fig=TRUE, width=8, height=10, include=FALSE>>=
par(mfrow=c(3, 4)); autocorr.plot(mcmc(covt[[ch]]), auto.layout=FALSE, ask=FALSE, bty="n")
<<acor3, fig=TRUE, width=8, height=10, include=FALSE>>=
par(mfrow=c(2, 2)); autocorr.plot(mcmc(mixture[[ch]]), auto.layout=FALSE, ask=FALSE, bty="n")
@ 
\begin{figure}[tbh]
  \centering  
  \caption{Autocorrelation for $\boldsymbol{\beta}$ and $\boldsymbol{\gamma}$ parameters.}
  \label{acor1}
  \includegraphics[width=6.5in, height=8in]{tandmob-acor1}
\end{figure}  

\begin{figure}[tbh]
  \centering  
  \caption{Autocorrelation for standard deviations and correlations of transformed random effects $\boldsymbol{d}_i$.}
  \label{acor2}
  \includegraphics[width=6.5in, height=8in]{tandmob-acor2}
\end{figure}  

\begin{figure}[tbh]
  \centering  
  \caption{Autocorrelation for mixture related parameters.}
  \label{acor3}
  \includegraphics[width=6.5in, height=5in]{tandmob-acor3}
\end{figure}  

Trace-plots for regression parameters $\boldsymbol{\beta}$, means of random effects
$\boldsymbol{\gamma}$, standard deviations and correlations of transformed random effects
$\boldsymbol{d}_i$ and overall mixture mean (intercept), mixture standard deviation (scale)
and number of mixture components. See Figures~\ref{trace1}, \ref{trace2}, \ref{trace3} for the results.
<<trace1, fig=TRUE, width=8, height=10, include=FALSE>>=
par(mfrow=c(3, 4)); traceplot2(mcmc(beta[[ch]]))
<<trace2, fig=TRUE, width=8, height=10, include=FALSE>>=
par(mfrow=c(3, 4)); traceplot2(mcmc(covt[[ch]]))
<<trace3, fig=TRUE, width=8, height=10, include=FALSE>>=
par(mfrow=c(2, 2)); traceplot2(mcmc(mixture[[ch]]))
@ 
\begin{figure}[tbh]
  \centering  
  \caption{Trace-plots for $\boldsymbol{\beta}$ and $\boldsymbol{\gamma}$ parameters.}
  \label{trace1}
  \includegraphics[width=6.5in, height=8in]{tandmob-trace1}
\end{figure}  

\begin{figure}[tbh]
  \centering  
  \caption{Trace-plots for standard deviations and correlations of transformed random effects $\boldsymbol{d}_i$.}
  \label{trace2}
  \includegraphics[width=6.5in, height=8in]{tandmob-trace2}
\end{figure}  

\begin{figure}[tbh]
  \centering  
  \caption{Trace-plots for mixture related parameters.}
  \label{trace3}
  \includegraphics[width=6.5in, height=5in]{tandmob-trace3}
\end{figure}  

Gelman-Rubin convergence diagnostics:
<<gelmanRubin>>=
gelm.beta <- gelman.diag(mbeta)
gelm.covt <- gelman.diag(mcovt)
gelm.mixture <- gelman.diag(mmixture)
rownames(gelm.beta$psrf) <- dimnames(mbeta[[1]])[[2]]
rownames(gelm.covt$psrf) <- dimnames(mcovt[[1]])[[2]]
rownames(gelm.mixture$psrf) <- dimnames(mmixture[[1]])[[2]]
<<pgelman1>>=
print(gelm.beta)
<<pgelman2>>=
print(gelm.covt)
<<pgelman3>>=
print(gelm.mixture)
@ 


%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\section{Posterior predictive error distribution}
Based separately on both chains (see Figure~\ref{errdens} for the result):
<<errorDensity1>>=
dens <- list()
dens[[1]] <- bayesDensity(dirsim[[1]], grid=seq(1.4, 2, by=0.005), stgrid=seq(-3, 2, by=0.05))
dens[[2]] <- bayesDensity(dirsim[[2]], grid=seq(1.4, 2, by=0.005), stgrid=seq(-3, 2, by=0.05))
@ 
Now, we can draw them (see Figure~\ref{errdens} for the result). Observe that conditional on $k$
we draw only densities for $k=1,\dots,10$.
<<errdens, fig=TRUE, width=8, height=10, include=FALSE>>=
par(mfrow = c(2, 2), bty="n")
plot(dens[[1]], standard=TRUE, dim.plot=FALSE, main="Standardized, chain 1", k.cond=0:10)
plot(dens[[1]], standard=FALSE, dim.plot=FALSE, main="Unstandardized, chain 1", k.cond=0:10)
plot(dens[[2]], standard=TRUE, dim.plot=FALSE, main="Standardized, chain 2", k.cond=0:10)
plot(dens[[2]], standard=FALSE, dim.plot=FALSE, main="Unstandardized, chain 2", k.cond=0:10)
@ 
\begin{figure}[tbh]
  \centering  
  \caption{Posterior predictive error densities.}
  \label{errdens}
  \includegraphics[width=6.5in, height=5in]{tandmob-errdens}
\end{figure}  

Finally, we perform cleaning of generated files:
<<cleaning, term=FALSE>>=
files1 <- dir("./tandchain1")
files2 <- dir("./tandchain2")
file.remove(paste("./tandchain1/", files1, sep = ""))
file.remove(paste("./tandchain2/", files2, sep = ""))
file.remove("tandchain1")
file.remove("tandchain2")
@ 

\end{document} 

